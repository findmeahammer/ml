{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tflite-model-maker\n",
    "\n",
    "!pip install -q pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if having problems with tf..\n",
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "#if these tests fail try the nightly build of  tflite-model-maker,  tflite-model-maker-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immediate-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1672.2386, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "final-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = 'C:/tfw/tflite/may20/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "american-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "validate_images = os.path.join(train_root_dir, 'validate/images')\n",
    "\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'validate/images'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'validate/images'))\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'validate/annotations'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'validate/annotations'))\n",
    "\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'train/images'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'train/images'))\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'train/annotations'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'train/annotations'))\n",
    "\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'test/images'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'test/images'))\n",
    "shutil.rmtree(os.path.join(train_root_dir, 'test/annotations'))\n",
    "os.makedirs(os.path.join(train_root_dir, 'test/annotations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collect-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "268\n",
      "31\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import random\n",
    "\n",
    "source_images = os.path.join(train_root_dir, 'images')\n",
    "source_annotations = os.path.join(train_root_dir, 'annotations')\n",
    "\n",
    "random.seed();\n",
    "\n",
    "images_list = os.listdir(source_images)\n",
    "\n",
    "random.shuffle(images_list)\n",
    "print(len(images_list))\n",
    "\n",
    "total_images = len(images_list)    #total images in your source\n",
    "train_count = int(total_images * 0.85) #training size 85% of total\n",
    "validation_count = int(total_images * 0.1) #validation size, 10% of total\n",
    "test_count = total_images -(train_count + validation_count)  #test size, 5/6% of total depending on rounding\n",
    "print(train_count)\n",
    "print(validation_count)\n",
    "print(test_count)\n",
    "#todo create function\n",
    "for file in images_list[:train_count]:\n",
    "    #print(file)\n",
    "    source_file = os.path.join(source_images,file)\n",
    "    #copy images\n",
    "    #print(source_file)\n",
    "    #print(os.path.join(train_root_dir, 'train/images',file))\n",
    "    shutil.copyfile(source_file, os.path.join(train_root_dir, 'train/images',file))\n",
    "    #copy annotation\n",
    "    annotation_file = os.path.splitext(file)[0] + '.xml'\n",
    "    shutil.copyfile(os.path.join(source_annotations,annotation_file), os.path.join(train_root_dir, 'train/annotations',annotation_file))\n",
    "\n",
    "for file in images_list[train_count:(train_count + validation_count)]:\n",
    "    #print(file)\n",
    "    source_file = os.path.join(source_images,file)\n",
    "    shutil.copyfile(source_file, os.path.join(train_root_dir, 'validate/images',file))\n",
    "    annotation_file = os.path.splitext(file)[0] + '.xml'\n",
    "    shutil.copyfile(os.path.join(source_annotations,annotation_file), os.path.join(train_root_dir, 'validate/annotations',annotation_file))\n",
    "    \n",
    "for file in images_list[(train_count + validation_count):]:\n",
    "    #print(file)\n",
    "    source_file = os.path.join(source_images,file)\n",
    "    shutil.copyfile(source_file, os.path.join(train_root_dir, 'test/images',file))\n",
    "    annotation_file = os.path.splitext(file)[0] + '.xml'\n",
    "    shutil.copyfile(os.path.join(source_annotations,annotation_file), os.path.join(train_root_dir, 'test/annotations',annotation_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map={1: \"dog\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grateful-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "###train\n",
    "\n",
    "image_dir = os.path.join(train_root_dir, 'train/images')\n",
    "annotations_dir =os.path.join(train_root_dir, 'train/annotations')\n",
    "output_train =os.path.join(train_root_dir,'tfrecord/train')\n",
    "\n",
    "max_images = 300\n",
    "object_detector.DataLoader.from_pascal_voc(image_dir, annotations_dir, label_map=label_map, cache_dir=output_train, max_num_images=max_images)\n",
    "train_images = len(os.listdir(image_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "separated-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "###validate\n",
    "image_dir = os.path.join(train_root_dir, 'validate/images')\n",
    "annotations_dir =os.path.join(train_root_dir, 'validate/annotations')\n",
    "output_dir =os.path.join(train_root_dir,'tfrecord/validate')\n",
    "max_images = 100\n",
    "object_detector.DataLoader.from_pascal_voc(image_dir, annotations_dir, label_map=label_map, cache_dir=output_dir, max_num_images=max_images)\n",
    "validate_images = len(os.listdir(image_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "positive-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "###test\n",
    "image_dir = os.path.join(train_root_dir, 'test/images')\n",
    "annotations_dir =os.path.join(train_root_dir, 'test/annotations')\n",
    "output_dir =os.path.join(train_root_dir,'tfrecord/test')\n",
    "max_images = 100\n",
    "object_detector.DataLoader.from_pascal_voc(image_dir, annotations_dir, label_map=label_map, cache_dir=output_dir, max_num_images=max_images)\n",
    "test_images = len(os.listdir(image_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "royal-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "31\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(train_images)\n",
    "print(validate_images)\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "golden-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size =train_images\n",
    "train_data = object_detector.DataLoader(\n",
    "    \"C:/tfw/tflite/may20/tfrecord/train/*.tfrecord\", data_set_size, label_map=label_map, annotations_json_file=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consecutive-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size =validate_images\n",
    "validation_data = object_detector.DataLoader(\n",
    "    \"C:/tfw/tflite/may20/tfrecord/validate/*.tfrecord\", data_set_size, label_map=label_map, annotations_json_file=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exposed-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size =test_images\n",
    "test_data = object_detector.DataLoader(\n",
    "    \"C:/tfw/tflite/may20/tfrecord/test/*.tfrecord\", data_set_size, label_map=label_map, annotations_json_file=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get('efficientdet_lite0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "checked-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 53s 351ms/step - det_loss: 1.5920 - cls_loss: 1.0355 - box_loss: 0.0111 - reg_l2_loss: 0.0630 - loss: 1.6550 - learning_rate: 0.0090 - gradient_norm: 2.0824 - val_det_loss: 1.3866 - val_cls_loss: 0.6407 - val_box_loss: 0.0149 - val_reg_l2_loss: 0.0630 - val_loss: 1.4496\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 8s 254ms/step - det_loss: 0.8656 - cls_loss: 0.5297 - box_loss: 0.0067 - reg_l2_loss: 0.0631 - loss: 0.9286 - learning_rate: 0.0100 - gradient_norm: 2.7517 - val_det_loss: 1.5387 - val_cls_loss: 0.9377 - val_box_loss: 0.0120 - val_reg_l2_loss: 0.0631 - val_loss: 1.6018\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 8s 253ms/step - det_loss: 0.5725 - cls_loss: 0.3434 - box_loss: 0.0046 - reg_l2_loss: 0.0631 - loss: 0.6356 - learning_rate: 0.0099 - gradient_norm: 2.4866 - val_det_loss: 1.1149 - val_cls_loss: 0.5388 - val_box_loss: 0.0115 - val_reg_l2_loss: 0.0632 - val_loss: 1.1780\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 8s 242ms/step - det_loss: 0.4122 - cls_loss: 0.2578 - box_loss: 0.0031 - reg_l2_loss: 0.0632 - loss: 0.4753 - learning_rate: 0.0099 - gradient_norm: 2.6008 - val_det_loss: 0.8684 - val_cls_loss: 0.4571 - val_box_loss: 0.0082 - val_reg_l2_loss: 0.0632 - val_loss: 0.9317\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 8s 237ms/step - det_loss: 0.3609 - cls_loss: 0.2258 - box_loss: 0.0027 - reg_l2_loss: 0.0632 - loss: 0.4241 - learning_rate: 0.0098 - gradient_norm: 2.3699 - val_det_loss: 0.6506 - val_cls_loss: 0.3149 - val_box_loss: 0.0067 - val_reg_l2_loss: 0.0633 - val_loss: 0.7139\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 8s 241ms/step - det_loss: 0.3045 - cls_loss: 0.1974 - box_loss: 0.0021 - reg_l2_loss: 0.0633 - loss: 0.3678 - learning_rate: 0.0097 - gradient_norm: 2.3425 - val_det_loss: 0.7394 - val_cls_loss: 0.4264 - val_box_loss: 0.0063 - val_reg_l2_loss: 0.0633 - val_loss: 0.8027\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 10s 310ms/step - det_loss: 0.2530 - cls_loss: 0.1755 - box_loss: 0.0016 - reg_l2_loss: 0.0633 - loss: 0.3163 - learning_rate: 0.0096 - gradient_norm: 1.9573 - val_det_loss: 0.7477 - val_cls_loss: 0.4560 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0633 - val_loss: 0.8111\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 8s 250ms/step - det_loss: 0.2549 - cls_loss: 0.1748 - box_loss: 0.0016 - reg_l2_loss: 0.0633 - loss: 0.3183 - learning_rate: 0.0094 - gradient_norm: 2.3506 - val_det_loss: 0.5347 - val_cls_loss: 0.3294 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0633 - val_loss: 0.5981\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 8s 238ms/step - det_loss: 0.2302 - cls_loss: 0.1595 - box_loss: 0.0014 - reg_l2_loss: 0.0634 - loss: 0.2935 - learning_rate: 0.0093 - gradient_norm: 2.1977 - val_det_loss: 0.6676 - val_cls_loss: 0.3274 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0634 - val_loss: 0.7309\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 8s 249ms/step - det_loss: 0.2299 - cls_loss: 0.1616 - box_loss: 0.0014 - reg_l2_loss: 0.0634 - loss: 0.2933 - learning_rate: 0.0091 - gradient_norm: 2.3300 - val_det_loss: 0.8045 - val_cls_loss: 0.4505 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.0634 - val_loss: 0.8679\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 8s 234ms/step - det_loss: 0.2345 - cls_loss: 0.1672 - box_loss: 0.0013 - reg_l2_loss: 0.0634 - loss: 0.2979 - learning_rate: 0.0089 - gradient_norm: 2.4055 - val_det_loss: 0.6062 - val_cls_loss: 0.3426 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0634 - val_loss: 0.6696\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 8s 243ms/step - det_loss: 0.2412 - cls_loss: 0.1681 - box_loss: 0.0015 - reg_l2_loss: 0.0634 - loss: 0.3046 - learning_rate: 0.0087 - gradient_norm: 2.6175 - val_det_loss: 0.5043 - val_cls_loss: 0.3356 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0634 - val_loss: 0.5677\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 8s 250ms/step - det_loss: 0.2150 - cls_loss: 0.1566 - box_loss: 0.0012 - reg_l2_loss: 0.0635 - loss: 0.2784 - learning_rate: 0.0085 - gradient_norm: 2.2664 - val_det_loss: 0.4442 - val_cls_loss: 0.3061 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0635 - val_loss: 0.5076\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 9s 263ms/step - det_loss: 0.2192 - cls_loss: 0.1547 - box_loss: 0.0013 - reg_l2_loss: 0.0635 - loss: 0.2826 - learning_rate: 0.0082 - gradient_norm: 2.5396 - val_det_loss: 0.4476 - val_cls_loss: 0.3147 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0635 - val_loss: 0.5111\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 10s 288ms/step - det_loss: 0.1949 - cls_loss: 0.1436 - box_loss: 0.0010 - reg_l2_loss: 0.0635 - loss: 0.2584 - learning_rate: 0.0080 - gradient_norm: 1.9371 - val_det_loss: 0.5166 - val_cls_loss: 0.3778 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0635 - val_loss: 0.5801\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 8s 240ms/step - det_loss: 0.1863 - cls_loss: 0.1396 - box_loss: 9.3452e-04 - reg_l2_loss: 0.0635 - loss: 0.2499 - learning_rate: 0.0077 - gradient_norm: 1.8023 - val_det_loss: 0.4823 - val_cls_loss: 0.2953 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0635 - val_loss: 0.5458\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 8s 236ms/step - det_loss: 0.2212 - cls_loss: 0.1663 - box_loss: 0.0011 - reg_l2_loss: 0.0635 - loss: 0.2847 - learning_rate: 0.0075 - gradient_norm: 2.2114 - val_det_loss: 0.5796 - val_cls_loss: 0.3836 - val_box_loss: 0.0039 - val_reg_l2_loss: 0.0635 - val_loss: 0.6431\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 8s 252ms/step - det_loss: 0.1778 - cls_loss: 0.1342 - box_loss: 8.7182e-04 - reg_l2_loss: 0.0635 - loss: 0.2413 - learning_rate: 0.0072 - gradient_norm: 1.6412 - val_det_loss: 0.4090 - val_cls_loss: 0.2715 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0635 - val_loss: 0.4725\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 8s 247ms/step - det_loss: 0.1685 - cls_loss: 0.1275 - box_loss: 8.1945e-04 - reg_l2_loss: 0.0635 - loss: 0.2320 - learning_rate: 0.0069 - gradient_norm: 1.8468 - val_det_loss: 0.3722 - val_cls_loss: 0.2546 - val_box_loss: 0.0024 - val_reg_l2_loss: 0.0635 - val_loss: 0.4357\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 8s 249ms/step - det_loss: 0.1592 - cls_loss: 0.1192 - box_loss: 7.9924e-04 - reg_l2_loss: 0.0635 - loss: 0.2227 - learning_rate: 0.0066 - gradient_norm: 1.5583 - val_det_loss: 0.3726 - val_cls_loss: 0.2745 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0635 - val_loss: 0.4362\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 8s 241ms/step - det_loss: 0.1632 - cls_loss: 0.1243 - box_loss: 7.7707e-04 - reg_l2_loss: 0.0635 - loss: 0.2267 - learning_rate: 0.0063 - gradient_norm: 1.5735 - val_det_loss: 0.4275 - val_cls_loss: 0.3276 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0635 - val_loss: 0.4911\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 10s 306ms/step - det_loss: 0.1521 - cls_loss: 0.1166 - box_loss: 7.0986e-04 - reg_l2_loss: 0.0635 - loss: 0.2156 - learning_rate: 0.0060 - gradient_norm: 1.4481 - val_det_loss: 0.3983 - val_cls_loss: 0.3224 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4619\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 8s 239ms/step - det_loss: 0.1720 - cls_loss: 0.1346 - box_loss: 7.4802e-04 - reg_l2_loss: 0.0635 - loss: 0.2355 - learning_rate: 0.0056 - gradient_norm: 1.8248 - val_det_loss: 0.4224 - val_cls_loss: 0.3090 - val_box_loss: 0.0023 - val_reg_l2_loss: 0.0635 - val_loss: 0.4859\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 8s 239ms/step - det_loss: 0.1437 - cls_loss: 0.1126 - box_loss: 6.2299e-04 - reg_l2_loss: 0.0635 - loss: 0.2073 - learning_rate: 0.0053 - gradient_norm: 1.4680 - val_det_loss: 0.4113 - val_cls_loss: 0.3094 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0635 - val_loss: 0.4748\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 8s 247ms/step - det_loss: 0.1478 - cls_loss: 0.1131 - box_loss: 6.9429e-04 - reg_l2_loss: 0.0635 - loss: 0.2113 - learning_rate: 0.0050 - gradient_norm: 1.6972 - val_det_loss: 0.4825 - val_cls_loss: 0.3743 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0635 - val_loss: 0.5460\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 8s 233ms/step - det_loss: 0.1614 - cls_loss: 0.1287 - box_loss: 6.5443e-04 - reg_l2_loss: 0.0635 - loss: 0.2249 - learning_rate: 0.0047 - gradient_norm: 1.9053 - val_det_loss: 0.3924 - val_cls_loss: 0.3104 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0635 - val_loss: 0.4559\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 8s 237ms/step - det_loss: 0.1581 - cls_loss: 0.1260 - box_loss: 6.4373e-04 - reg_l2_loss: 0.0635 - loss: 0.2217 - learning_rate: 0.0044 - gradient_norm: 1.9949 - val_det_loss: 0.3826 - val_cls_loss: 0.3114 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4462\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 8s 256ms/step - det_loss: 0.1569 - cls_loss: 0.1226 - box_loss: 6.8651e-04 - reg_l2_loss: 0.0635 - loss: 0.2204 - learning_rate: 0.0040 - gradient_norm: 1.7471 - val_det_loss: 0.3975 - val_cls_loss: 0.3160 - val_box_loss: 0.0016 - val_reg_l2_loss: 0.0635 - val_loss: 0.4611\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 287ms/step - det_loss: 0.1617 - cls_loss: 0.1282 - box_loss: 6.7114e-04 - reg_l2_loss: 0.0635 - loss: 0.2253 - learning_rate: 0.0037 - gradient_norm: 1.8386 - val_det_loss: 0.4306 - val_cls_loss: 0.3445 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.4942\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 8s 253ms/step - det_loss: 0.1413 - cls_loss: 0.1131 - box_loss: 5.6511e-04 - reg_l2_loss: 0.0635 - loss: 0.2049 - learning_rate: 0.0034 - gradient_norm: 1.5926 - val_det_loss: 0.4088 - val_cls_loss: 0.3221 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0635 - val_loss: 0.4723\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 229ms/step - det_loss: 0.1443 - cls_loss: 0.1170 - box_loss: 5.4630e-04 - reg_l2_loss: 0.0635 - loss: 0.2079 - learning_rate: 0.0031 - gradient_norm: 1.7920 - val_det_loss: 0.4097 - val_cls_loss: 0.3169 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0635 - val_loss: 0.4732\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 8s 249ms/step - det_loss: 0.1279 - cls_loss: 0.1033 - box_loss: 4.9229e-04 - reg_l2_loss: 0.0635 - loss: 0.1915 - learning_rate: 0.0028 - gradient_norm: 1.4555 - val_det_loss: 0.3857 - val_cls_loss: 0.3109 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4492\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 8s 238ms/step - det_loss: 0.1451 - cls_loss: 0.1165 - box_loss: 5.7178e-04 - reg_l2_loss: 0.0635 - loss: 0.2086 - learning_rate: 0.0025 - gradient_norm: 1.6095 - val_det_loss: 0.3610 - val_cls_loss: 0.2918 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4245\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 8s 252ms/step - det_loss: 0.1368 - cls_loss: 0.1086 - box_loss: 5.6566e-04 - reg_l2_loss: 0.0635 - loss: 0.2004 - learning_rate: 0.0023 - gradient_norm: 1.7150 - val_det_loss: 0.3589 - val_cls_loss: 0.2821 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4224\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 8s 235ms/step - det_loss: 0.1324 - cls_loss: 0.1074 - box_loss: 4.9962e-04 - reg_l2_loss: 0.0635 - loss: 0.1959 - learning_rate: 0.0020 - gradient_norm: 1.6978 - val_det_loss: 0.3465 - val_cls_loss: 0.2782 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4100\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 10s 305ms/step - det_loss: 0.1292 - cls_loss: 0.1023 - box_loss: 5.3837e-04 - reg_l2_loss: 0.0635 - loss: 0.1927 - learning_rate: 0.0018 - gradient_norm: 1.7126 - val_det_loss: 0.3697 - val_cls_loss: 0.2939 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4332\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 8s 252ms/step - det_loss: 0.1160 - cls_loss: 0.0928 - box_loss: 4.6469e-04 - reg_l2_loss: 0.0635 - loss: 0.1796 - learning_rate: 0.0015 - gradient_norm: 1.5458 - val_det_loss: 0.3792 - val_cls_loss: 0.3139 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.4427\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 8s 235ms/step - det_loss: 0.1252 - cls_loss: 0.1006 - box_loss: 4.9150e-04 - reg_l2_loss: 0.0635 - loss: 0.1887 - learning_rate: 0.0013 - gradient_norm: 1.7050 - val_det_loss: 0.3647 - val_cls_loss: 0.2953 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4282\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 8s 233ms/step - det_loss: 0.1280 - cls_loss: 0.1024 - box_loss: 5.1048e-04 - reg_l2_loss: 0.0635 - loss: 0.1915 - learning_rate: 0.0011 - gradient_norm: 1.6987 - val_det_loss: 0.3521 - val_cls_loss: 0.2747 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4156\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 8s 244ms/step - det_loss: 0.1095 - cls_loss: 0.0862 - box_loss: 4.6737e-04 - reg_l2_loss: 0.0635 - loss: 0.1731 - learning_rate: 9.0004e-04 - gradient_norm: 1.4038 - val_det_loss: 0.3681 - val_cls_loss: 0.2952 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0635 - val_loss: 0.4316\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 228ms/step - det_loss: 0.1189 - cls_loss: 0.0946 - box_loss: 4.8568e-04 - reg_l2_loss: 0.0635 - loss: 0.1824 - learning_rate: 7.2520e-04 - gradient_norm: 1.5838 - val_det_loss: 0.3598 - val_cls_loss: 0.2907 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4233te: 7.5511e-04\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 8s 245ms/step - det_loss: 0.1314 - cls_loss: 0.1079 - box_loss: 4.6999e-04 - reg_l2_loss: 0.0635 - loss: 0.1949 - learning_rate: 5.6793e-04 - gradient_norm: 1.9245 - val_det_loss: 0.3800 - val_cls_loss: 0.3097 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4435\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 8s 239ms/step - det_loss: 0.1242 - cls_loss: 0.0997 - box_loss: 4.8871e-04 - reg_l2_loss: 0.0635 - loss: 0.1877 - learning_rate: 4.2887e-04 - gradient_norm: 1.5629 - val_det_loss: 0.3817 - val_cls_loss: 0.3110 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4452\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 10s 302ms/step - det_loss: 0.1153 - cls_loss: 0.0934 - box_loss: 4.3710e-04 - reg_l2_loss: 0.0635 - loss: 0.1788 - learning_rate: 3.0860e-04 - gradient_norm: 1.5887 - val_det_loss: 0.3872 - val_cls_loss: 0.3198 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.4507\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 8s 251ms/step - det_loss: 0.1135 - cls_loss: 0.0931 - box_loss: 4.0698e-04 - reg_l2_loss: 0.0635 - loss: 0.1770 - learning_rate: 2.0760e-04 - gradient_norm: 1.4647 - val_det_loss: 0.3938 - val_cls_loss: 0.3266 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.4573\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 224ms/step - det_loss: 0.1073 - cls_loss: 0.0873 - box_loss: 4.0062e-04 - reg_l2_loss: 0.0635 - loss: 0.1708 - learning_rate: 1.2630e-04 - gradient_norm: 1.3397 - val_det_loss: 0.3885 - val_cls_loss: 0.3211 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0635 - val_loss: 0.4520\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 8s 238ms/step - det_loss: 0.1261 - cls_loss: 0.1027 - box_loss: 4.6744e-04 - reg_l2_loss: 0.0635 - loss: 0.1896 - learning_rate: 6.5024e-05 - gradient_norm: 1.6546 - val_det_loss: 0.3888 - val_cls_loss: 0.3210 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4524\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 228ms/step - det_loss: 0.1219 - cls_loss: 0.0973 - box_loss: 4.9175e-04 - reg_l2_loss: 0.0635 - loss: 0.1854 - learning_rate: 2.4027e-05 - gradient_norm: 1.5340 - val_det_loss: 0.3875 - val_cls_loss: 0.3188 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4510\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 8s 249ms/step - det_loss: 0.1182 - cls_loss: 0.0945 - box_loss: 4.7420e-04 - reg_l2_loss: 0.0635 - loss: 0.1818 - learning_rate: 3.4770e-06 - gradient_norm: 1.6883 - val_det_loss: 0.3887 - val_cls_loss: 0.3205 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4522\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 8s 237ms/step - det_loss: 0.1162 - cls_loss: 0.0939 - box_loss: 4.4537e-04 - reg_l2_loss: 0.0635 - loss: 0.1797 - learning_rate: 3.4587e-06 - gradient_norm: 1.6348 - val_det_loss: 0.3860 - val_cls_loss: 0.3180 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.4495\n"
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, batch_size=8, train_whole_model=True, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-excuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "liable-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir ='C:/tfw/tflite/may20/export'\n",
    "#model.export(export_dir=out_dir)\n",
    "model.export(export_dir=out_dir, export_format=[ExportFormat.SAVED_MODEL, ExportFormat.LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "shared-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir ='C:/tfw/tflite/may20/export'\n",
    "\n",
    "model.export(export_dir=out_dir, tflite_filename='may25model.tflite', export_format=ExportFormat.TFLITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-coffee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-aspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "generous-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "model_path = out_dir + '/may25model.tflite'\n",
    "\n",
    "# Load the labels into a list\n",
    "classes = ['???'] * model.model_spec.config.num_classes\n",
    "label_map = model.model_spec.config.label_map\n",
    "for label_id, label_name in label_map.as_dict().items():\n",
    "  classes[label_id-1] = label_name\n",
    "\n",
    "# Define a list of colors for visualization\n",
    "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
    "\n",
    "def preprocess_image(image_path, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "  img = tf.io.read_file(image_path)\n",
    "  img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "  original_image = img\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  return resized_img, original_image\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, image):\n",
    "  \"\"\"Set the input tensor.\"\"\"\n",
    "  tensor_index = interpreter.get_input_details()[0]['index']\n",
    "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "  input_tensor[:, :] = image\n",
    "\n",
    "\n",
    "def get_output_tensor(interpreter, index):\n",
    "  \"\"\"Retur the output tensor at the given index.\"\"\"\n",
    "  output_details = interpreter.get_output_details()[index]\n",
    "  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def detect_objects(interpreter, image, threshold):\n",
    "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "  # Feed the input image to the model\n",
    "  set_input_tensor(interpreter, image)\n",
    "  interpreter.invoke()\n",
    "  \n",
    "  # Get all outputs from the model\n",
    "  boxes = get_output_tensor(interpreter, 0)\n",
    "  classes = get_output_tensor(interpreter, 1)\n",
    "  scores = get_output_tensor(interpreter, 2)\n",
    "  count = int(get_output_tensor(interpreter, 3))\n",
    "\n",
    "  results = []\n",
    "  for i in range(count):\n",
    "    if scores[i] >= threshold:\n",
    "      result = {\n",
    "        'bounding_box': boxes[i],\n",
    "        'class_id': classes[i],\n",
    "        'score': scores[i]\n",
    "      }\n",
    "      results.append(result)\n",
    "  return results\n",
    "\n",
    "\n",
    "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
    "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
    "  # Load the input shape required by the model\n",
    "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "  # Load the input image and preprocess it\n",
    "  preprocessed_image, original_image = preprocess_image(\n",
    "      image_path,\n",
    "      (input_height, input_width)\n",
    "    )\n",
    "\n",
    "  # Run object detection on the input image\n",
    "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
    "\n",
    "  # Plot the detection results on the input image\n",
    "  original_image_np = original_image.numpy().astype(np.uint8)\n",
    "  for obj in results:\n",
    "    # Convert the object bounding box from relative coordinates to absolute\n",
    "    # coordinates based on the original image resolution\n",
    "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
    "    xmin = int(xmin * original_image_np.shape[1])\n",
    "    xmax = int(xmax * original_image_np.shape[1])\n",
    "    ymin = int(ymin * original_image_np.shape[0])\n",
    "    ymax = int(ymax * original_image_np.shape[0])\n",
    "\n",
    "    # Find the class index of the current object\n",
    "    class_id = int(obj['class_id'])\n",
    "\n",
    "    # Draw the bounding box and label on the image\n",
    "    color = [int(c) for c in COLORS[class_id]]\n",
    "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "    # Make adjustments to make the label visible for all objects\n",
    "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
    "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
    "    cv2.putText(original_image_np, label, (xmin, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "  # Return the final image\n",
    "  original_uint8 = original_image_np.astype(np.uint8)\n",
    "  return original_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "TEMP_FILE = 'C:/tfw/eval/PXL_20210304_134057864.jpg'\n",
    "DETECTION_THRESHOLD = 0.3\n",
    "\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "#for image_path in TEST_IMAGE_PATHS:\n",
    "    # Run inference and draw detection result on the local copy of the original file\n",
    "detection_result_image = run_odt_and_draw_results(\n",
    "    TEMP_FILE,\n",
    "    interpreter,\n",
    "    threshold=DETECTION_THRESHOLD\n",
    ")\n",
    "\n",
    "# Show the detection result\n",
    "Image.fromarray(detection_result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-denmark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
